{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMSegmentation training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import mmseg\n",
    "import mmcv\n",
    "\n",
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from mmseg.apis import set_random_seed\n",
    "\n",
    "from mmcv import Config\n",
    "\n",
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5mNQuc2GsVE"
   },
   "source": [
    "## Define and Transform dataset\n",
    "Les variables ci-dessous sont à modifier pour correspondre à ton dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '../../mm_dataset'\n",
    "img_dir = 'images'\n",
    "ann_dir = 'labels'\n",
    "\n",
    "classes = ('frame', 'road_network','water', 'blocks', 'non-built' )\n",
    "palette = [[0, 0, 0], [255, 255, 255],[0, 0, 255], [255, 0, 255], [0, 255, 255]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule ci-dessous permet de transformer les labels de format RGB dans le bon format pour MMSegmentation.\n",
    "\n",
    "Pour que cette transformation ne soit pas \"in-place\", les labels sont lus dans le dossier qui se trouve à `original_labels_path`. Il faut donc changer cette variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnGZfribFHCx"
   },
   "outputs": [],
   "source": [
    "def rgb_to_str(rgb):\n",
    "    return str(rgb[0])+str(rgb[1])+str(rgb[2])\n",
    "\n",
    "palette_str = [rgb_to_str(x) for x in palette]\n",
    "\n",
    "conversion_dict = {k:v for k,v in zip(palette_str, range(palette))}\n",
    "\n",
    "original_labels_path = \"path/to/original_labels\"\n",
    "\n",
    "for file in mmcv.scandir(osp.join(data_root, original_labels_path), suffix='.png'):\n",
    "    seg_img = Image.open(osp.join(data_root, original_labels_path, file))\n",
    "    data = np.asarray(seg_img).astype(np.uint8)\n",
    "    for x in range(len(data)):\n",
    "        for y in range(len(data[0])):\n",
    "            rgb_str = rgb_to_str(data[x][y])\n",
    "            data[x][y] = conversion_dict[rgb_str]\n",
    "\n",
    "    data=data[:,:,0]\n",
    "    seg_img = Image.fromarray(data).convert(\"P\")\n",
    "    seg_img.putpalette(np.array(palette, dtype=np.uint8))\n",
    "    seg_img.save(osp.join(data_root, ann_dir, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule ci-dessous permet de diviser les données en train et test set. Chez moi, les fichiers de test portaient le nom \"\\_val\", mais pour changer la manière dont on choisit ces 2 ensembles, tu peux changer le code là où je l'ai mis en évidence avec des commentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dir = 'splits'\n",
    "mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n",
    "filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(osp.join(data_root, ann_dir), suffix='.png')]\n",
    "\n",
    "train_list = []\n",
    "val_list = []\n",
    "for filename in filename_list:\n",
    "    # Code à changer ici suivant la logique de distribution du train et test set\n",
    "    if \"_val\" in filename:\n",
    "        val_list.append(filename)\n",
    "    else:\n",
    "        train_list.append(filename)\n",
    "        \n",
    "        \n",
    "print(len(train_list))\n",
    "print(len(val_list))\n",
    "with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n",
    "    f.writelines(line + '\\n' for line in train_list)\n",
    "with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
    "    f.writelines(line + '\\n' for line in val_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette cellule-ci permet de calculer la moyenne et la déviation standard des couleurs des images utilisées. Ces valeurs sont demandées par MMSegmentation pour la normalisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(3)\n",
    "b = np.zeros(3)\n",
    "c = 0\n",
    "for file in mmcv.scandir(osp.join(data_root, img_dir), suffix='.png'):\n",
    "    seg_img = Image.open(osp.join(data_root, img_dir, file))\n",
    "    data = np.asarray(seg_img).astype(np.uint8)\n",
    "    mean = np.mean(data, axis=(0, 1))\n",
    "    std = np.std(data, axis=(0,1))\n",
    "    a+=mean\n",
    "    b+=std\n",
    "    c+=1\n",
    "print(f\"Mean : {a/c}\")\n",
    "print(f\"Std : {b/c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HchvmGYB_rrO"
   },
   "source": [
    "Définition de la classe qui représente le Dataset. A priori rien à changer, si ce n'est éventuellement le nom de la classe, et le format des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbsWOw62_o-X"
   },
   "outputs": [],
   "source": [
    "@DATASETS.register_module()\n",
    "class ParisDataset(CustomDataset):\n",
    "    CLASSES = classes\n",
    "    PALETTE = palette\n",
    "    def __init__(self, split, **kwargs):\n",
    "        super().__init__(img_suffix='.png', seg_map_suffix='.png', split=split, **kwargs)\n",
    "        assert osp.exists(self.img_dir) and self.split is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUVtmn3Iq3WA",
    "tags": []
   },
   "source": [
    "## Create a config file\n",
    "\n",
    "Création de la configuration à partir de celle de OCRNet. J'ai essayé de mettre en évidence avec des commentaires les variables à modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyKnYC1Z7iCV",
    "outputId": "6195217b-187f-4675-994b-ba90d8bb3078",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('configs/ocrnet/ocrnet_hr48_512x1024_160k_cityscapes.py')\n",
    "\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head[0].norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head[1].norm_cfg = cfg.norm_cfg\n",
    "\n",
    "\n",
    "cfg.model.decode_head[0].num_classes = len(classes)\n",
    "cfg.model.decode_head[1].num_classes = len(classes)\n",
    "\n",
    "cfg.checkpoint_config.meta = dict(\n",
    "    CLASSES=classes,\n",
    "    PALETTE=palette)\n",
    "\n",
    "#Modifier la string suivante pour qu'elle porte le nom de la classe du Dataset défini plus haut\n",
    "cfg.dataset_type = 'ParisDataset'\n",
    "cfg.data_root = data_root\n",
    "\n",
    "cfg.data.samples_per_gpu =4\n",
    "cfg.data.workers_per_gpu=4\n",
    "\n",
    "#Le fameux endroit où la moyenne et la déviation standard des images sont demandées\n",
    "cfg.img_norm_cfg = dict(mean=[197.850,  186.04, 161.41], std=[38.38, 38.34, 36.56], to_rgb=True)\n",
    "\n",
    "#La pipileline d'entrainement peut être modifiée ci-dessous\n",
    "cfg.crop_size = (512, 512)\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    #dict(type='Resize', img_scale=(1000, 1000), ratio_range=(0.75, 1)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.25),\n",
    "    #dict(type=\"RandomRotate\", prob=0.25, degree=30),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "#La pipileline de test peut être modifiée ci-dessous\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(1000, 1000),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            #dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.img_dir = img_dir\n",
    "cfg.data.train.ann_dir = ann_dir\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = 'splits/train.txt'\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.img_dir = img_dir\n",
    "cfg.data.val.ann_dir = ann_dir\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = 'splits/val.txt'\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "cfg.data.test.img_dir = img_dir\n",
    "cfg.data.test.ann_dir = ann_dir\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'splits/val.txt'\n",
    "\n",
    "\n",
    "#Changer la string pour pointer vers les poids pré-entrainés. Si jamais, pour cette config, tu peux les trouver ici : https://github.com/open-mmlab/mmsegmentation/tree/master/configs/ocrnet\n",
    "cfg.load_from = './work_dirs/RN101.pt'\n",
    "\n",
    "#Pointe vers le dossier où les poids seront enregistrés\n",
    "cfg.work_dir = './work_dirs/clip'\n",
    "\n",
    "#A modifier selon ce que l'on souhaite\n",
    "cfg.runner.max_iters = 10000\n",
    "cfg.log_config.interval = 100\n",
    "cfg.evaluation.interval = 300\n",
    "cfg.checkpoint_config.interval = 300\n",
    "\n",
    "\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "\n",
    "#Je ne sais pas s'il y aura quelque chose à modifier ici pour choisir le GPU que tu veux utiliser. Comme je n'en ai que 1, je n'ai pas eu ce problème.\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "#Politique de l'optimizer et du LR à modifier\n",
    "cfg.optimizer = dict(type='SGD', lr=0.001,momentum=0.9, weight_decay=0.0005)\n",
    "cfg.optimizer_config = dict(type='Fp16OptimizerHook', loss_scale=512.0, distributed=False)\n",
    "cfg.lr_config = dict(policy='poly', power=0.9, min_lr=0.0001, by_epoch=False)\n",
    "\n",
    "#On peut print la config à la fin si on le souhaite\n",
    "#print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWuH14LYF2gQ"
   },
   "source": [
    "## Train and Quick test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lance l'entrainement. Ceci est du code quasiment copié-collé, donc il ne devrait rien avoir à changer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYKoSfdMF12B",
    "outputId": "422219ca-d7a5-4890-f09f-88c959942e64",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_segmentor(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "model.PALETTE = datasets[0].PALETTE\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
    "                meta=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEkWOP-NMbc_"
   },
   "source": [
    "Pour se faire une idée des résultats, on peut rapidement afficher une prédiction sur une image. Il faut évidemment changer le path de l'image de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "ekG__UfaH_OU",
    "outputId": "1437419c-869a-4902-df86-d4f6f8b2597a"
   },
   "outputs": [],
   "source": [
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette\n",
    "\n",
    "img = mmcv.imread(data_root+'/images/12148_btv1b8439505gf1_0_val.png')\n",
    "model.cfg = cfg\n",
    "result = inference_segmentor(model, img)\n",
    "\n",
    "show_result_pyplot(model, img, result, palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "MMSegmentation Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
