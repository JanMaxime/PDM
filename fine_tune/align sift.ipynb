{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc744f-c328-4d1f-881c-351939b38a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import  Image, ImageDraw\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import scipy.ndimage as ndi\n",
    "import cv2 as cv\n",
    "from align import *\n",
    "import pickle\n",
    "import math\n",
    "import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "import glob\n",
    "sift = cv.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cdef38-e5a0-453a-b71c-2846c3cd386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_neighbours(points1, points2, descriptors1, descriptors2, radius=150):\n",
    "    '''\n",
    "    Get all the similar neighbours of points1 in points2 in selected radius\n",
    "    '''\n",
    "    neigh = NearestNeighbors(radius=radius)\n",
    "    neigh.fit(points2)\n",
    "    neighboring_indices = neigh.radius_neighbors(points1, return_distance=False)\n",
    "    similar_neighbours = []\n",
    "    for i, neighbours in enumerate(neighboring_indices):\n",
    "        if len(neighbours) == 0:\n",
    "            similar_neighbours.append(np.empty((0)))\n",
    "            continue\n",
    "        similarities = cosine_similarity(descriptors1[i].reshape(1,-1), descriptors2[neighbours])[0]\n",
    "        sorting = np.argsort(similarities)[::-1]\n",
    "        similar_neighbours.append(neighbours[sorting])\n",
    "    return similar_neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78044afc-a4d5-4ab7-bfda-3e6ce71880b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('maps_data.pickle', 'rb') as handle:\n",
    "    maps_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20005cce-e95a-481d-b179-f55094032019",
   "metadata": {},
   "outputs": [],
   "source": [
    "selems = list()\n",
    "selems.append(np.array([[0, 1, 0], [1, 1, 1], [0, 0, 0]]))\n",
    "selems.append(np.array([[1, 0, 1], [0, 1, 0], [1, 0, 0]]))\n",
    "selems.append(np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0]]))\n",
    "selems.append(np.array([[0, 1, 0], [1, 1, 0], [0, 0, 1]]))\n",
    "selems.append(np.array([[0, 0, 1], [1, 1, 1], [0, 1, 0]]))\n",
    "selems = [np.rot90(selems[i], k=j) for i in range(5) for j in range(4)]\n",
    "\n",
    "selems.append(np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]]))\n",
    "selems.append(np.array([[1, 0, 1], [0, 1, 0], [1, 0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30027d9-4092-403e-80e6-761bf188c576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sift_size = 19\n",
    "radius = 175\n",
    "\n",
    "#Intersections, sift for baseline\n",
    "baseline = cv.imread(\"baseline.png\", cv.IMREAD_GRAYSCALE)\n",
    "baseline_branches = np.zeros_like(baseline, dtype=bool)\n",
    "for selem in selems:\n",
    "    baseline_branches |= ndi.binary_hit_or_miss(baseline, selem)\n",
    "\n",
    "baseline_points = np.argwhere(baseline_branches)\n",
    "\n",
    "baseline_keypoints = list()\n",
    "for point in baseline_points:\n",
    "    baseline_keypoints.append(cv.KeyPoint(float(point[1]), float(point[0]), sift_size))\n",
    "baseline_keypoints, baseline_descriptors = sift.compute(baseline,baseline_keypoints)\n",
    "baseline_points = [keypoint.pt for keypoint in baseline_keypoints]\n",
    "\n",
    "for map_name in tqdm.tqdm(glob.glob(\"warped_maps_skeleton/*.png\")):\n",
    "    try:\n",
    "        #Load the map image, search the intersections, and compute sift\n",
    "        test_image = cv.imread(map_name, cv.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        test_branches = np.zeros_like(test_image, dtype=bool)\n",
    "        for selem in selems:\n",
    "            test_branches |= ndi.binary_hit_or_miss(test_image, selem)\n",
    "        test_points = np.argwhere(test_branches)\n",
    "\n",
    "        test_keypoints = list()\n",
    "        for point in test_points:\n",
    "            test_keypoints.append(cv.KeyPoint(float(point[1]), float(point[0]), sift_size))\n",
    "        test_keypoints, test_descriptors = sift.compute(test_image,test_keypoints)\n",
    "        test_points = [keypoint.pt for keypoint in test_keypoints]\n",
    "\n",
    "        s1 = get_similar_neighbours(test_points, baseline_points, test_descriptors, baseline_descriptors, radius=radius)\n",
    "        s2 = get_similar_neighbours(baseline_points,test_points, baseline_descriptors,test_descriptors, radius=radius)\n",
    "\n",
    "        src_pts = []\n",
    "        dst_pts = []\n",
    "        for i,s in enumerate(s1):\n",
    "            if len(s) == 0:\n",
    "                continue\n",
    "            if i == s2[s[0]][0]:\n",
    "                src_pts.append(test_points[i])\n",
    "                dst_pts.append(baseline_points[s[0]])\n",
    "        src_pts = np.array(src_pts)\n",
    "        dst_pts = np.array(dst_pts)\n",
    "\n",
    "        new_M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "        \n",
    "        test_image = cv.warpPerspective(test_image, new_M, (baseline.shape[1], baseline.shape[0]))\n",
    "        map_name = map_name[21:]\n",
    "        plt.imsave(f\"realigned/{map_name}\", test_image)\n",
    "        \n",
    "    except:\n",
    "        print(\"error\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acfe371-6d7c-42a3-b283-ff77496e7916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sift_size = 19\n",
    "radius = 75\n",
    "\n",
    "#Intersections, sift for baseline\n",
    "baseline = cv.imread(\"warped_maps/baseline.png\", cv.IMREAD_GRAYSCALE)\n",
    "baseline_branches = np.zeros_like(baseline, dtype=bool)\n",
    "for selem in selems:\n",
    "    baseline_branches |= ndi.binary_hit_or_miss(baseline, selem)\n",
    "\n",
    "baseline_points = np.argwhere(baseline_branches)\n",
    "\n",
    "baseline_keypoints = list()\n",
    "for point in baseline_points:\n",
    "    baseline_keypoints.append(cv.KeyPoint(float(point[1]), float(point[0]), sift_size))\n",
    "baseline_keypoints, baseline_descriptors = sift.compute(baseline,baseline_keypoints)\n",
    "baseline_points = [keypoint.pt for keypoint in baseline_keypoints]\n",
    "\n",
    "patch_size = 2000\n",
    "original_height = baseline.shape[0]\n",
    "original_width = baseline.shape[1]\n",
    "\n",
    "for map_name, M, distance in tqdm.tqdm(maps_data):\n",
    "    final = np.zeros_like(baseline)\n",
    "    #Load the map image, search the intersections, and compute sift\n",
    "    test_image = cv.imread(f\"warped_maps/{map_name}.png\", cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "    test_branches = np.zeros_like(test_image, dtype=bool)\n",
    "    for selem in selems:\n",
    "        test_branches |= ndi.binary_hit_or_miss(test_image, selem)\n",
    "    test_points = np.argwhere(test_branches)\n",
    "    \n",
    "    for patch_x in range(0, baseline.shape[1], patch_size):\n",
    "        for patch_y in range(0,baseline.shape[0], patch_size):\n",
    "            \n",
    "            if baseline.shape[1] - patch_x < patch_size or baseline.shape[0] - patch_y < patch_size:\n",
    "                continue\n",
    "            height = [patch_y, patch_y+patch_size]\n",
    "            width = [patch_x, patch_x+patch_size]\n",
    "            \n",
    "            current_test_keypoints = list()\n",
    "            for point in test_points:\n",
    "                if (patch_x <= point[1] <= patch_x+patch_size) and (patch_y <= point[0] <= patch_y+patch_size):\n",
    "                    current_test_keypoints.append(cv.KeyPoint(float(point[1]), float(point[0]), sift_size))\n",
    "\n",
    "            current_test_keypoints, test_descriptors = sift.compute(test_image,current_test_keypoints)\n",
    "            current_test_points = [keypoint.pt for keypoint in current_test_keypoints]\n",
    "\n",
    "            try:\n",
    "                s1 = get_similar_neighbours(current_test_points, baseline_points, test_descriptors, baseline_descriptors, radius=radius)\n",
    "                s2 = get_similar_neighbours(baseline_points,current_test_points, baseline_descriptors,test_descriptors, radius=radius)\n",
    "\n",
    "                src_pts = []\n",
    "                dst_pts = []\n",
    "                for i,s in enumerate(s1):\n",
    "                    if len(s) == 0:\n",
    "                        continue\n",
    "                    if i == s2[s[0]][0]:\n",
    "                        src_pts.append(current_test_points[i])\n",
    "                        dst_pts.append(baseline_points[s[0]])\n",
    "                src_pts = np.array(src_pts)\n",
    "                dst_pts = np.array(dst_pts)\n",
    "\n",
    "                new_M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "                image_patch = test_image[max(0,height[0]-radius):min(height[1]+radius, original_height), max(0,width[0]-radius):min(width[1]+radius, original_width)]\n",
    "                warped_patch = cv.warpPerspective(image_patch, new_M, (image_patch.shape[1], image_patch.shape[0]))\n",
    "                final[max(0,height[0]-radius):min(height[1]+radius, original_height), max(0,width[0]-radius):min(width[1]+radius, original_width)] = warped_patch\n",
    "            except:\n",
    "                final[max(0,height[0]-radius):min(height[1]+radius, original_height), max(0,width[0]-radius):min(width[1]+radius, original_width)] = test_image[max(0,height[0]-radius):min(height[1]+radius, original_height), max(0,width[0]-radius):min(width[1]+radius, original_width)]\n",
    "            #plt.imsave(f\"test/after_{patch_x}_{patch_y}.png\", warped_patch/2 + baseline[max(0,height[0]-radius):min(height[1]+radius, original_height), max(0,width[0]-radius):min(width[1]+radius, original_width)])\n",
    "    plt.imsave(f\"realigned_patch/{map_name}.png\", final/2+baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dfc137-deaf-4a95-a97e-89bc4e3647a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sift_sizes = [19]\n",
    "radii = [175]\n",
    "ameliorations = []\n",
    "distances = []\n",
    "for sift_size in tqdm.tqdm(sift_sizes):\n",
    "    \n",
    "    #Intersections, sift for baseline\n",
    "    baseline = cv.imread(\"warped_maps_validation/baseline.png\", cv.IMREAD_GRAYSCALE)\n",
    "    baseline_branches = np.zeros_like(baseline, dtype=bool)\n",
    "    for selem in selems:\n",
    "        baseline_branches |= ndi.binary_hit_or_miss(baseline, selem)\n",
    "\n",
    "    baseline_points = np.argwhere(baseline_branches)\n",
    "\n",
    "    baseline_keypoints = list()\n",
    "    for point in baseline_points:\n",
    "        baseline_keypoints.append(cv.KeyPoint(float(point[1]), float(point[0]), sift_size))\n",
    "    baseline_keypoints, baseline_descriptors = sift.compute(baseline,baseline_keypoints)\n",
    "    baseline_points = [keypoint.pt for keypoint in baseline_keypoints]\n",
    "    ameliorations_radius = [0]*len(radii)\n",
    "    for map_name, M, distance in tqdm.tqdm(maps_data):\n",
    "        try:\n",
    "            with open(f\"points_transformed/{map_name}.json\", \"r\") as test_points_json:\n",
    "\n",
    "                #Load test points and apply the previous homography\n",
    "                test_points = json.load(test_points_json)\n",
    "                pts = np.float32([[x,y] for x,y in zip(test_points[\"x\"], test_points[\"y\"])]).reshape(-1,1,2)\n",
    "                targets = np.float32([[x,y] for x,y in zip(test_points[\"x_\"], test_points[\"y_\"])])\n",
    "                p_transformed = cv.perspectiveTransform(pts,M)\n",
    "\n",
    "                #Load the map image, search the intersections, and compute sift\n",
    "                test_image = cv.imread(f\"warped_maps_validation/{map_name}.png\", cv.IMREAD_GRAYSCALE)\n",
    "                test_branches = np.zeros_like(test_image, dtype=bool)\n",
    "                for selem in selems:\n",
    "                    test_branches |= ndi.binary_hit_or_miss(test_image, selem)\n",
    "                test_points = np.argwhere(test_branches)\n",
    "\n",
    "                test_keypoints = list()\n",
    "                for point in test_points:\n",
    "                    test_keypoints.append(cv.KeyPoint(float(point[1]), float(point[0]), sift_size))\n",
    "                test_keypoints, test_descriptors = sift.compute(test_image,test_keypoints)\n",
    "                test_points = [keypoint.pt for keypoint in test_keypoints]\n",
    "\n",
    "                for index, radius in enumerate(radii):\n",
    "                    s1 = get_similar_neighbours(test_points, baseline_points, test_descriptors, baseline_descriptors, radius=radius)\n",
    "                    s2 = get_similar_neighbours(baseline_points,test_points, baseline_descriptors,test_descriptors, radius=radius)\n",
    "\n",
    "                    src_pts = []\n",
    "                    dst_pts = []\n",
    "                    for i,s in enumerate(s1):\n",
    "                        if len(s) == 0:\n",
    "                            continue\n",
    "                        if i == s2[s[0]][0]:\n",
    "                            src_pts.append(test_points[i])\n",
    "                            dst_pts.append(baseline_points[s[0]])\n",
    "                    src_pts = np.array(src_pts)\n",
    "                    dst_pts = np.array(dst_pts)\n",
    "\n",
    "                    new_M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC,5.0)\n",
    "                    p_transformed_2 = cv.perspectiveTransform(p_transformed,new_M).reshape(-1,2)\n",
    "\n",
    "                    distance_test = [math.sqrt((target_x - p_transformed_x)**2 + (target_y - p_transformed_y)**2) for ((target_x, target_y), (p_transformed_x, p_transformed_y)) in zip (targets, p_transformed_2)]\n",
    "                    distances+=distance_test\n",
    "\n",
    "        except:\n",
    "            print(\"error\")\n",
    "            continue\n",
    "            \n",
    "    ameliorations.append(ameliorations_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f944ccdc-5d99-48c4-be96-fa0747f8c886",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c946d-ee25-4822-825e-3eed0e2c64da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
